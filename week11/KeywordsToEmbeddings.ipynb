{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What do word vectors represent?\n",
    "\n",
    "On Monday we saw the result of running a word embedding algorithm on two collections. We \"embed\" words in a vector space, such that words that are subtitutable (\"ship\" and \"boat\") or that occur together (\"Stop\" and \"thief!\").\n",
    "\n",
    "In today's work we will look at the intuition for how the properties of embedding vectors relate to properties we can directly observe in texts. They are really just representations of the words that occur near a given word.\n",
    "\n",
    "What can we tell about a word from the words that occur near it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, sys, math\n",
    "from IPython.display import display, clear_output, Markdown, Latex\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions to nicely display numeric word scores\n",
    "\n",
    "def show(sorted_words, n=20):\n",
    "    markdown_table = \"|Score | Word|\\n|---:|:---|\\n\"\n",
    "    for score, word in sorted_words[:n]:\n",
    "        markdown_table += \"|{:.3f}|{}|\\n\".format(score, word)\n",
    "    display(Markdown(markdown_table))\n",
    "    \n",
    "def show_counter(counter, n=20):\n",
    "    markdown_table = \"|Count | Word|\\n|---:|:---|\\n\"\n",
    "    for word, score in counter.most_common(n):\n",
    "        markdown_table += \"|{}|{}|\\n\".format(score, word)\n",
    "    display(Markdown(markdown_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll read the texts. I've already split the tokens with Spacy and written the output to a file with one sentence per line, so punctuation will be included as distinct tokens.\n",
    "\n",
    "While we read this, we'll also count the frequency of each word type in `all_counter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_filename = \"../data/Sagas/sagas_en_split.txt\"\n",
    "\n",
    "sentences = []\n",
    "all_counter = Counter()\n",
    "\n",
    "with open(text_filename, encoding=\"utf-8\") as reader:\n",
    "    for line in reader:\n",
    "        ## The file has already been tokenized, so we can split on whitespace\n",
    "        tokens = line.strip().split()\n",
    "        all_counter.update(tokens)\n",
    "        \n",
    "        sentences.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by looking at the context that words appear in. The next block defines a *key word in context* (KWIC) view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_in_context(query):\n",
    "    table_markdown = \"|left context|word|right context|\\n|--:|--|:--|\\n\"\n",
    "    for sentence in sentences:\n",
    "        \n",
    "        if not query in sentence:\n",
    "            continue\n",
    "            \n",
    "        for i, word in enumerate(sentence):\n",
    "            if word == query:\n",
    "                start = max(i-window_size, 0)\n",
    "                left_context = sentence[start:i]\n",
    "                right_context = sentence[(i+1):(i+window_size+1)]\n",
    "                table_markdown += \"|{}|{}|{}|\\n\".format(\" \".join(left_context), word, \" \".join(right_context))\n",
    "                    \n",
    "    display(Markdown(table_markdown))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "\n",
    "I've given you an example, for *Shetland*, a chain of islands north of Scotland near the Orkney islands. \n",
    "\n",
    "Add 10 additional cells, each with one call to the `keyword_in_context` function. Choose five pairs of words that you think might be similar (e.g. *Shetland* and *Orkneys*). Select a variety of parts of speech, such as nouns, verbs, adjectives, prepositions, and proper names.\n",
    "\n",
    "Discuss what you notice about the similarities and differences between the contexts of these words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_in_context(\"Shetland\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more `keyword_in_context` cells here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the distribution of words immediately preceding (*left* or *previous* context) and immediately following (*right* or *next* context) a word. This block creates two dictionaries, which map a string to the `Counter` of the words that follow that word and precede it, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_context_counters = {} # count words that precede the key\n",
    "next_context_counters = {} # count words that follow the key\n",
    "\n",
    "for sentence in sentences:\n",
    "    for i in range(len(sentence) - 1): # stop at the next-to-last token\n",
    "        word = sentence[i]\n",
    "        next_word = sentence[i+1]\n",
    "        \n",
    "        if not word in next_context_counters:\n",
    "            next_context_counters[word] = Counter()\n",
    "        if not next_word in previous_context_counters:\n",
    "            previous_context_counters[next_word] = Counter()\n",
    "        \n",
    "        next_context_counters[word][next_word] += 1\n",
    "        previous_context_counters[next_word][word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "In the next code cell I'm demonstrating how to get the most frequent following words for a query word.\n",
    "\n",
    "Use this function like a \"predictive text\" feature. Generate two Viking sentences of 10-20 words.\n",
    "* In the first sentence, start with \"Then\" and pick the most frequent following word. Record your sentence, and comment on why always picking the most common word might not be a good idea.\n",
    "* In the second sentence, start with \"Then\" but choose the next word based on both the frequency distribution and your artistic sensibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First sentence here**\n",
    "\n",
    "\n",
    "**Comment on first sentence**\n",
    "\n",
    "\n",
    "**Second sentence here**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add cells to show previous *and* next context words for at least 10 more words. Use a selection of nouns, verbs, adjectives, prepositions, and names. These may be the same words you looked at before, but you may also want to add additional examples.\n",
    "\n",
    "Discuss whether the words to the right or left of a word indicate its part of speech. Cite examples to support your argument. Are the two contexts equally informative for a given part of speech, and is that consistent across different parts of speech?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_counter(next_context_counters[\"she\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_counter(previous_context_counters[\"she\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add cells here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll look at sums over the full five-word context window. This code creates one `Counter` for each word type, which adds up all the words that appear within the window around the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_counters = {}\n",
    "\n",
    "for sentence in sentences:\n",
    "    \n",
    "    for i, word in enumerate(sentence):\n",
    "        start = max(i-window_size, 0)\n",
    "        left_context = sentence[start:i]\n",
    "        right_context = sentence[(i+1):(i+window_size+1)]\n",
    "        \n",
    "        if not word in word_context_counters:\n",
    "            word_context_counters[word] = Counter()\n",
    "        \n",
    "        word_context_counters[word].update(left_context)\n",
    "        word_context_counters[word].update(right_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "This next cell is an example showing output for the full context counts of a word, essentially adding up all the words you saw in the KWIC view earlier.\n",
    "\n",
    "Show output for at least 10 words, from a mix of parts of speech.\n",
    "\n",
    "Discuss how this view of a word's context differs from the single-previous-word and single-next-word context views we saw in Part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_counter(word_context_counters[\"Shetland\"], 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add cells here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's look at a way of comparing the word frequencies we actually observed to the word frequencies in the collection as a whole. We'll use a method called *pointwise mutual information*.\n",
    "\n",
    "PMI is closely related to KL divergence. In this case, the two distributions we want to compare are the probability of context word $c$ *near* word $w$ and the probabilty of $c$ anywhere. The word *the* is common throughout the collection, so we expect to see it. This metric measures the ratio between the frequency that we actually saw it in the context and our expectation for any random context.\n",
    "\n",
    "Notation: \n",
    "* $N(c|w)$ is `word_context_counters[w][c]`\n",
    "* $N(w)$ is `sum(word_context_counters[w].values()`\n",
    "* $N(c)$ is `all_counter[c]`\n",
    "* $N$ is `all_sum`\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "PMI(c, w) & = P(c, w) \\log \\frac{P(c,w)}{P(c)P(w)} \\\\\n",
    "& = P(c, w) \\log \\frac{P(c|w)P(w)}{P(c)P(w)} \\\\\n",
    "& = P(c, w) \\log \\frac{P(c|w)}{P(c)} \\\\\n",
    "& \\propto N(c|w) \\log \\frac{\\frac{N(c|w)}{N(w)} }{ \\frac{N(c)}{N}  } \\\\\n",
    "& = N(c|w) \\log \\frac{N(c|w)N}{N(w)N(c)}\n",
    "\\end{align}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_ratio(word):\n",
    "    counter = word_context_counters[word]\n",
    "    \n",
    "    all_sum = sum(all_counter.values()) ## N\n",
    "    word_sum = sum(counter.values())    ## N(w)\n",
    "    \n",
    "    comparisons = []\n",
    "    for c in counter.keys():\n",
    "        score = counter[c] * math.log((counter[c] * all_sum) / (word_sum * all_counter[c]))\n",
    "        comparisons.append((score, c))\n",
    "    \n",
    "    return sorted(comparisons, reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "\n",
    "Compare results using this `log_ratio` function to the output of the `nearest` function used in Monday's notebook.\n",
    "\n",
    "Provide some examples, and describe how they are similar or different from the output of the word embedding. If there are \"missing\" words in the output here that are close in the embedding space, show the `log_ratio` output for those words. Do the two words have similar context words? Describe whether this is true and mention examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 'spae' is a Scots word for prophecy. Gunnhilda was the wife of Eric Bloodaxe.\n",
    "## She was ordered to be drowned in a bog by King Harald Bluetooth, the namesake\n",
    "## of the wireless standard. Think about that next time you put on some headphones.\n",
    "\n",
    "show(log_ratio(\"queen\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add cells with examples here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra bonus for those interested** The embedding algorithm adds an additional step: subsampling the most frequent words. Here's code that generates this subsampling probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_probs = {}\n",
    "all_sum = sum(all_counter.values())\n",
    "for word in all_counter.keys():\n",
    "    p_word = all_counter[word] / all_sum\n",
    "    score = 1.0 / (10000 * p_word)\n",
    "    sampling_probs[word] = math.sqrt(score) + score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
