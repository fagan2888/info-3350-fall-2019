{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%load_ext cython\n",
    "\n",
    "import re, sys, random, math\n",
    "from collections import Counter\n",
    "from timeit import default_timer as timer\n",
    "from IPython.display import display, clear_output, Markdown, Latex\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "word_pattern = re.compile(\"\\w[\\w\\-\\']*\\w|\\w\")\n",
    "\n",
    "import pronouncing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the documents file\n",
    "        \n",
    "word_counts = Counter()\n",
    "documents = []\n",
    "\n",
    "for line in open(\"sonnets.tsv\", encoding=\"utf-8\"):    \n",
    "    (poem_id, time_period, genre, text) = line.rstrip().split(\"\\t\")\n",
    "    \n",
    "    lines = [ word_pattern.findall(line) for line in text.split(\"|\") ]\n",
    "    \n",
    "    documents.append({ \"original\": line, \"lines\": lines,\n",
    "                      \"poem_id\": poem_id, \"time_period\": time_period, \"genre\": genre })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 60\n",
    "doc_topic_probs = np.load(\"poetry_doc_topics.npy\")\n",
    "word_topic_probs = np.load(\"poetry_word_topics.npy\")\n",
    "vocabulary = np.load(\"vocabulary.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_words(topic, n_words=12):\n",
    "    sorted_words = sorted(zip(word_topic_probs[:,topic], vocabulary), reverse=True)\n",
    "    return \" \".join([w for x, w in sorted_words[:n_words]])\n",
    "\n",
    "def print_all_topics():\n",
    "    for topic in range(num_topics):\n",
    "        print(topic, topic_words(topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_docs(topic, n_docs=10):\n",
    "    for doc_id in np.argsort(-doc_topic_probs[:,topic])[:n_docs]:\n",
    "        print(\"{} {:.1f}% | {}\".format(doc_id, 100 * doc_topic_probs[doc_id,topic], documents[doc_id][\"original\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_period_counter = Counter([d[\"time_period\"] for d in documents])\n",
    "\n",
    "time_period_counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_periods = ['Fifteenth-Century Poetry', 'Tudor 1500-1580',\n",
    "                'Jacobean and Caroline 1603-1660', 'Restoration 1660-1700',\n",
    "                'Early Eighteenth-Century 1700-1749',\n",
    "                'Later Eighteenth-Century 1750-1799', 'Early Nineteenth-Century 1800-1834', \n",
    "                'Mid Nineteenth-Century 1835-1869', 'Later Nineteenth-Century 1870-1899',\n",
    "                'Twentieth-Century 1900-1999']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhyme(line):\n",
    "    last_word = line[-1]\n",
    "    phones = pronouncing.phones_for_word(last_word)\n",
    "    rhymes = [pronouncing.rhyming_part(p) for p in phones]\n",
    "    \n",
    "    return (last_word.lower(), set(rhymes))\n",
    "\n",
    "def sorted_tuple(a, b):\n",
    "    if a < b:\n",
    "        return (a, b)\n",
    "    else:\n",
    "        return (b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_num = 0\n",
    "\n",
    "time_period_rhymes = {}\n",
    "\n",
    "for time_period in time_periods:\n",
    "    time_period_rhymes[time_period] = Counter()\n",
    "\n",
    "for document in documents:\n",
    "    \n",
    "    time_period = document[\"time_period\"]\n",
    "    if not time_period in time_period_rhymes:\n",
    "        continue\n",
    "    \n",
    "    ## each element is tuple (word, {set of possible rhymes})\n",
    "    rhymes = [ rhyme(line) for line in document[\"lines\"] if len(line) > 0 ]\n",
    "    \n",
    "    ## compare every word to every previous word\n",
    "    for i in range(1, len(rhymes)):\n",
    "        word_info_a = rhymes[i]\n",
    "        for j in range(0, i):\n",
    "            word_info_b = rhymes[j]\n",
    "            \n",
    "            ## look for set intersection of rhyme sets\n",
    "            if word_info_a[1] & word_info_b[1]:\n",
    "                # if there is a rhyme, record the two words in a tuple\n",
    "                rhyme_pair = sorted_tuple(word_info_a[0], word_info_b[0])\n",
    "                time_period_rhymes[time_period][rhyme_pair] += 1\n",
    "                \n",
    "                # only count a rhyme once\n",
    "                break\n",
    "\n",
    "    line_num += 1\n",
    "    #if line_num > 100:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time_period in time_periods:\n",
    "    print(time_period)\n",
    "    print(time_period_rhymes[time_period].most_common(30))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
