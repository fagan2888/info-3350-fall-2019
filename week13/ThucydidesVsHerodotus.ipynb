{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Dunning's log-likelihood test, Multiple hypotheses.\n",
    "\n",
    "Can an observation be significant but not convincing?\n",
    "\n",
    "In text mining we often count things and compare \n",
    "proportions. Frequently we can count the same thing\n",
    "in different contexts, like a word in two different\n",
    "novels. If we want to make claims about differences\n",
    "between contexts, we need to know whether an observed\n",
    "difference could have arisen by random chance.\n",
    "We can use Ted Dunning's\n",
    "G<sup>2</sup> metric as an indicator of significance, but how does \n",
    "the number of words we test affect our evaluation of \n",
    "significance?\n",
    "\n",
    "First, refresh your memory about Dunning's G<sup>2</sup>:\n",
    "\n",
    "1. As we did last week, try a few different proportions.\n",
    "Record the output of dunning_score(...) here.\n",
    "\n",
    "2. What score do you think indicates a difference that you\n",
    "would consider convincing evidence that two observed\n",
    "proportions are really different?\n",
    "\n",
    "Now let's look at the difference between two Greek\n",
    "historians, Herodotus and Thucydides.\n",
    "\n",
    "3. Run `print_nicely(word_scores[:50])`. Copy the output here.\n",
    "How do the observed Dunning G scores compare to your expectation?\n",
    "\n",
    "4. What are the most \"surprising\" words according to \n",
    "the Dunning score? Search through the documents for examples.\n",
    "What did you learn about the content and the style of these\n",
    "two historians?\n",
    "\n",
    "We're looking at about 5000 distinct tests, one for each\n",
    "word. Should we be worried? Let's simulate random\n",
    "word distributions.\n",
    "\n",
    "5. Now create two lists, `fake_herodotus` and `fake_thucydides`\n",
    "using the `shuffle_lists()` function with the `herodotus_tokens`\n",
    "and `thucydides_tokens` lists as input. Record the length of\n",
    "all four lists here, and confirm that the new ones have\n",
    "the same length as the original `_tokens` lists.\n",
    "\n",
    "6. Now use the \"fake\" token lists to create `fake_scores`.\n",
    "Use `print_nicely()` and array slices (ie [:50], etc) to look\n",
    "at the range of Dunning scores. How do the \"most significant\" \n",
    "scores compare to your expectations about significance?\n",
    "Would you have been fooled if you didn't realize that\n",
    "these results were random?\n",
    "\n",
    "7. Thucydides writes \"for it is the habit of humans to trust\n",
    "the things they desire to unexamined hope, but to confront\n",
    "the things they reject with the full force of reason.\" \n",
    "How is this relevant to our discussions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math, re, random\n",
    "\n",
    "word_pattern = re.compile(\"\\w[\\w\\-\\']*\\w|\\w\")\n",
    "\n",
    "thucydides_tokens = []\n",
    "herodotus_tokens = []\n",
    "\n",
    "with open(\"../data/thuc_herod/thucydides.txt\", encoding=\"utf-8\") as thucydides:\n",
    "    for line in thucydides:\n",
    "        thucydides_tokens.extend(word_pattern.findall(line))\n",
    "    \n",
    "with open(\"../data/thuc_herod/herodotus.txt\", encoding=\"utf-8\") as herodotus:\n",
    "    for line in herodotus:\n",
    "        herodotus_tokens.extend(word_pattern.findall(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate the \"surprise factor\" of two proportions that are expressed as counts.\n",
    "###  ie x1 \"heads\" out of n1 flips.\n",
    "def dunning_score(x1, n1, x2, n2):\n",
    "    p1 = float(x1) / n1\n",
    "    p2 = float(x2) / n2\n",
    "    p = float(x1 + x2) / (n1 + n2)\n",
    "    \n",
    "    return -2 * ( x1 * math.log(p / p1) + (n1 - x1) * math.log((1 - p)/(1 - p1)) + \n",
    "                  x2 * math.log(p / p2) + (n2 - x2) * math.log((1 - p)/(1 - p2)) )\n",
    "\n",
    "def score_differences(a, b):\n",
    "    a_counter = Counter(a)\n",
    "    b_counter = Counter(b)\n",
    "\n",
    "    a_length = len(a)\n",
    "    b_length = len(b)\n",
    "    vocabulary = a_counter.keys() & b_counter.keys()\n",
    "    \n",
    "    scored_words = []\n",
    "    \n",
    "    for w in vocabulary:\n",
    "        a_n = a_counter[w]\n",
    "        b_n = b_counter[w]\n",
    "        \n",
    "        ## Create a tuple containing information about each word\n",
    "        g_score = dunning_score(a_n, a_length, b_n, b_length)\n",
    "        scored_words.append( (g_score, a_n, b_n, w) )\n",
    "        scored_words.sort(reverse = True)\n",
    "    \n",
    "    return scored_words\n",
    "\n",
    "def shuffle_lists(a, b):\n",
    "    a_length = len(a)\n",
    "    b_length = len(b)\n",
    "    \n",
    "    merged = list(a)\n",
    "    merged.extend(b)\n",
    "    random.shuffle(merged)\n",
    "    \n",
    "    return (merged[:a_length], merged[a_length:])\n",
    "\n",
    "## Low-res bar plot\n",
    "bars = [\"  \", \"\\u2581\", \"\\u2582\", \"\\u2583\", \"\\u2584\", \"\\u2585\", \"\\u2586\", \"\\u2587\", \"\\u2588\"]\n",
    "\n",
    "def unicode_barplot(x, y):\n",
    "    ratio = round(7 * (x / (x+y)))\n",
    "    return bars[ratio] + bars[7-ratio]\n",
    "\n",
    "def print_nicely(scores):\n",
    "    for word_info in scores:\n",
    "        print(\"{:.3f}\\t{}\\t{}\\t{}\\t{}\".format(word_info[0], unicode_barplot(word_info[1], word_info[2]), word_info[1], word_info[2], word_info[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" \".join(bars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dunning_score(1, 100, 99, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_scores = score_differences(herodotus_tokens, thucydides_tokens)\n",
    "print_nicely(word_scores[:30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
