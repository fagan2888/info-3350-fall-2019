{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis testing, songs vs. poems\n",
    "\n",
    "Song lyrics look a lot like poems. They both have a number of short lines, \n",
    "they often rhyme, and they are written with careful attention to sound,\n",
    "emotion, and aesthetics. Some songs started as poems, like the Star Spangled\n",
    "Banner. So what distinguishes them?\n",
    "\n",
    "[Be aware: Song lyrics have not been filtered for content. I expect the \n",
    "classroom to remain a respectful place. You are adults and I have no \n",
    "doubt that you can deal with this!]\n",
    "\n",
    "**On paper** Before looking at any data, what do you think will be the differences between \n",
    "song lyrics and short poems? Will we be able to distinguish them reliably?\n",
    "\n",
    "In this script we'll be examining a method for finding distinctive words between\n",
    "two groups of texts: Dunning's g-test. This method tests if the difference \n",
    "between two proportions (e.g. word frequencies) are significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math, re, random\n",
    "import numpy\n",
    "\n",
    "word_pattern = re.compile(\"\\w[\\w\\-\\']*\\w|\\w\")\n",
    "\n",
    "songs = []\n",
    "songs_counter = Counter()\n",
    "poems = []\n",
    "poems_counter = Counter()\n",
    "\n",
    "with open(\"../data/songs_poems/songs.txt\", encoding=\"utf-8\") as songs_reader:\n",
    "    for line in songs_reader:\n",
    "        tokens = word_pattern.findall(line)\n",
    "        songs.append(tokens)\n",
    "        songs_counter.update(tokens)\n",
    "    \n",
    "with open(\"../data/songs_poems/poems.txt\", encoding=\"utf-8\") as poems_reader:\n",
    "    for line in poems_reader:\n",
    "        tokens = word_pattern.findall(line)\n",
    "        poems.append(tokens)\n",
    "        poems_counter.update(tokens)\n",
    "\n",
    "word_counts = songs_counter + poems_counter\n",
    "\n",
    "## All the distinct word types in descending order by frequency\n",
    "vocabulary = [x[0] for x in word_counts.most_common()]\n",
    "vocabulary = vocabulary[0:1000]\n",
    "vocab_size = len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Song vs Poem Classification\n",
    "\n",
    "Now let's try classifying documents as poems or songs using a Naive Bayes classifier.\n",
    "\n",
    "1. What accuracy do you expect if we do a leave-one-out evaluation?\n",
    "\n",
    "[Response here]\n",
    "\n",
    "2. Run the `calculate_accuracy()` function. Record the accuracy. Are you surprised?\n",
    "\n",
    "[Response here]\n",
    "\n",
    "3. By default I'm classifying based on the 1000 most frequent words. Try three other frequency ranges. For example, to use the 50th to 100th most frequent words modify the approriate line to:\n",
    "\n",
    "    vocabulary = vocabulary[50:100]\n",
    "\n",
    "How do these affect accuracy? Give examples of the words in each range.\n",
    "\n",
    "[Response here]\n",
    "\n",
    "3. Use the `predict()` function to construct a list of (score, poem_tokens) tuples. Sort this list, and find the most song-ey poem and the most poem-ey poem. Do the same for songs.\n",
    "\n",
    "[Describe extreme poems here]\n",
    "\n",
    "[Describe extreme songs here]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(doc, smoothing=0.01):\n",
    "    ## loop through each word and add the log ratio\n",
    "    ## for that word. poem-ish words will have a negative score,\n",
    "    ##  song-ish words will have a positive score.\n",
    "    score = 0.0\n",
    "    \n",
    "    songs_length = sum(songs_counter.values())\n",
    "    poems_length = sum(poems_counter.values())\n",
    "    \n",
    "    for token in doc:\n",
    "        if token in vocabulary:\n",
    "            p_song = (songs_counter[token] + smoothing) / (songs_length + smoothing * vocab_size)\n",
    "            p_poem = (poems_counter[token] + smoothing) / (poems_length + smoothing * vocab_size)\n",
    "            score += math.log(p_song / p_poem)\n",
    "            \n",
    "    return score\n",
    "\n",
    "def calculate_accuracy():\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    for doc in songs:\n",
    "        songs_counter.subtract(doc)\n",
    "        score = predict(doc)\n",
    "        if score >= 0.0:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        songs_counter.update(doc)\n",
    "    \n",
    "    for doc in poems:\n",
    "        poems_counter.subtract(doc)\n",
    "        score = predict(doc)\n",
    "        if score < 0.0:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        poems_counter.update(doc)\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def print_nicely(scores):\n",
    "    for word_info in scores:\n",
    "        print(\"{}\\t{}\\t{}\\t{}\".format(word_info[0], word_info[1], word_info[2], word_info[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Word comparisons\n",
    "\n",
    "Dunning's g test is similar to the *Fightin' Words* plots and Burrows' $z$-scores we were looking at before. It takes into account the number of observations we have (ie word counts).\n",
    "\n",
    "For this script we'll be comparing songs and poems. \n",
    "We'll read the documents and then perform Dunning's \n",
    "g-test for each term in the overall vocabulary.\n",
    "\n",
    "1. Use Markdown syntax to create a contingency table for these values:\n",
    "    Group 1: 10 out of 50, Group 2: 5 out of 50.\n",
    "\n",
    "[Answer here]\n",
    "\n",
    "2. Using the `dunning_score` function, calculate Dunning\n",
    "   g-scores for the following proportions:\n",
    "   \n",
    "   (a) 100/120, 30/55\n",
    "   \n",
    "   (b) 100/120, 10/12\n",
    "   \n",
    "   (c) 45/100, 105/200\n",
    "   \n",
    "   (d) 0/5, 10/25.\n",
    "   \n",
    "   How do differences in proportions and differences in counts affect the \n",
    "   resulting g-scores?\n",
    "\n",
    "[Answer here]\n",
    "\n",
    "3. What does the magnitude of a g-score indicate? (Try adding a zero to every number)\n",
    "\n",
    "[Answer here]\n",
    "\n",
    "\n",
    "4. Dunning's G score tells us whether the difference in counts between two groups is significant, but it doesn't tell us which group uses that word more. Modify the code in `score_differences()` to return a *negative* G score if a wordis more probable in poems than in songs.\n",
    "\n",
    "[Change in code]\n",
    "\n",
    "5. Use this command to generate positive/negative Dunning scores:\n",
    "\n",
    "    word_scores = score_differences(songs_counter, poems_counter)\n",
    "\n",
    "Copy the output here. Which words are most indicative of songs, and which of\n",
    "poems? What does that result tell you about poetry and songs? Comment both on\n",
    "\"stopwords\" and on more content-bearing words.\n",
    "\n",
    "[Response here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.binomial(1000, 0.05, size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dunning_score(500, 10000, 470, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate the \"surprise factor\" of two proportions that are expressed as counts.\n",
    "###  ie x1 \"heads\" out of n1 flips.\n",
    "def dunning_score(x1, n1, x2, n2):\n",
    "    p1 = float(x1) / n1\n",
    "    p2 = float(x2) / n2\n",
    "    p = float(x1 + x2) / (n1 + n2)\n",
    "    \n",
    "    return -2 * ( x1 * math.log(p / p1) + (n1 - x1) * math.log((1 - p)/(1 - p1)) + \n",
    "                  x2 * math.log(p / p2) + (n2 - x2) * math.log((1 - p)/(1 - p2)) )\n",
    "\n",
    "def score_differences(a_counter, b_counter):\n",
    "    a_length = sum(a_counter.values())\n",
    "    b_length = sum(b_counter.values())\n",
    "    \n",
    "    shared_vocabulary = a_counter.keys() & b_counter.keys()\n",
    "    \n",
    "    scored_words = []\n",
    "    \n",
    "    for w in shared_vocabulary:\n",
    "        a_n = a_counter[w]\n",
    "        b_n = b_counter[w]\n",
    "        \n",
    "        g_score = dunning_score(a_n, b_n, a_length, b_length)\n",
    "        \n",
    "        ## The score is always positive, so add in a sign \n",
    "        ##  to indicate which proportion is larger.\n",
    "        ## If the word is more frequent in poems, negate it.\n",
    "        ## If the word is more frequent in songs, do nothing.\n",
    "        ### [ADD CODE HERE]\n",
    "        \n",
    "        ## Create a tuple containing information about each word\n",
    "        scored_words.append( (round(g_score, 3), a_n, b_n, w) )\n",
    "        scored_words.sort(reverse = True)\n",
    "    \n",
    "    return scored_words\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
